# Global State Vector 2.0: Multi-Scale Control for Autonomous AI Agents

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8+-green.svg)](https://www.python.org/)
[![Status](https://img.shields.io/badge/Status-MVP-orange.svg)]()
[![CI](https://github.com/dukeru115/GSV/workflows/CI/badge.svg)](https://github.com/dukeru115/GSV/actions)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

> **Implementation of GSV 2.0 framework for strategic adaptation in autonomous agents**  
> Based on: Urmanov, T., Gadeev, K., & Iusupov, B. (2025). *Global State Vector 2.0: Multi-Scale Control for Autonomous AI Agents*

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Architecture](#architecture)
- [Modules](#modules)
- [Examples](#examples)
- [Theory](#theory)
- [API Reference](#api-reference)
- [Contributing](#contributing)

---

## ğŸ¯ Overview

**GSV 2.0** provides a mathematically rigorous framework for **strategic adaptation** in AI agents through multi-scale control. Unlike traditional fixed hyperparameters or black-box meta-learning, GSV uses a low-dimensional dynamical system to modulate fast-layer cognitive processes based on accumulated experience.

### Key Features

âœ… **Mathematically Rigorous**: Proven stability guarantees via Lyapunov theory  
âœ… **Interpretable**: Four explicit control axes with clear semantics  
âœ… **Robust**: Prevents pathological states through stochastic dynamics  
âœ… **Adaptive**: Responds to environmental regime changes  
âœ… **Framework-Agnostic**: Works with Q-learning, DQN, PPO, LLMs, etc.

### The Four Axes

```
S(t) = [SA(t), SE(t), SP(t), SS(t)]
```

| Axis | Name | Controls | Active Inference Interpretation |
|------|------|----------|--------------------------------|
| **SA** | Arousal | Resource mobilization under stress | Expected precision on sensory errors |
| **SE** | Exploration | Novelty-seeking vs. reliable strategies | Epistemic value weighting |
| **SP** | Plasticity | Architectural change rate | Meta-learning rate |
| **SS** | Social | Multi-agent coordination | Precision on social priors |

---

## ğŸš€ Installation

### Quick Install (3 steps)

```bash
# 1. Clone the repository
git clone https://github.com/dukeru115/GSV.git
cd GSV

# 2. Install dependencies
pip install -r requirements.txt

# 3. Verify installation
python gsv2_tests.py
```

### Using pip (Alternative)

```bash
# Install from source
pip install -e .

# Or install specific dependencies
pip install numpy>=1.20.0 matplotlib>=3.3.0 scipy>=1.6.0
```

For detailed installation instructions, see [INSTALL.md](INSTALL.md).

### Files Structure

```
GSV/
â”œâ”€â”€ gsv2_core.py                # Core GSV implementation (SDE solver, metrics)
â”œâ”€â”€ gsv2_qlearning.py           # Q-learning integration wrapper
â”œâ”€â”€ gsv2_analysis.py            # Stability analysis & diagnostics
â”œâ”€â”€ gsv2_gridworld_demo.py      # Full demo (3000 episodes)
â”œâ”€â”€ gsv2_stress_demo.py         # Stress response scenario
â”œâ”€â”€ gsv2_experiments.py         # Parameter studies & ablations
â”œâ”€â”€ gsv2_tests.py               # Comprehensive test suite
â”œâ”€â”€ gsv2_quickstart.py          # Learning examples & patterns
â”œâ”€â”€ examples/                   # Simple usage examples
â”‚   â”œâ”€â”€ simple_example.py       # Minimal working example
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ setup.py                    # Package setup
â”œâ”€â”€ pyproject.toml              # Modern Python packaging
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ Summary.md                  # Complete implementation summary
â”œâ”€â”€ QUICKSTART.md               # 5-minute getting started guide
â”œâ”€â”€ INSTALL.md                  # Detailed installation guide
â””â”€â”€ CONTRIBUTING.md             # Contribution guidelines
```

---

## âš¡ Quick Start

### Basic Usage

```python
from gsv2_core import GSV2Controller, GSV2Params, MetricComputer

# Initialize with balanced parameters
gsv = GSV2Controller(GSV2Params())
metrics_computer = MetricComputer()

# Agent loop
for step in range(1000):
    # Your agent acts and learns
    td_error = agent.update(state, action, reward, next_state)
    
    # Compute GSV metrics
    stress = metrics_computer.compute_stress(td_error)
    coherence = metrics_computer.compute_coherence(policy_probs)
    novelty = metrics_computer.compute_novelty(state)
    
    metrics = {
        'rho_def': stress,
        'R': coherence,
        'novelty': novelty,
        'SIR': 0.0,  # For multi-agent
        'F': reward
    }
    
    # Update GSV (slow dynamics)
    gsv.step(metrics, dt=1.0)
    
    # Modulate agent parameters
    from gsv2_core import ModulationFunctions as MF
    gsv_state = gsv.get_state()
    
    epsilon = MF.epsilon_exploration(gsv_state['E'])
    alpha = MF.alpha_learning(gsv_state['P'])
    
    agent.set_epsilon(epsilon)
    agent.set_alpha(alpha)
```

### Run Complete Demo

```bash
python gsv2_gridworld_demo.py
```

This runs a **3000-episode** experiment with **regime changes** at episodes 1000 and 2000, demonstrating:
- Initial exploration phase
- Stable exploitation after learning
- Adaptive response to environmental shifts
- Guaranteed recovery through bounded dynamics

---

## ğŸ—ï¸ Architecture

### Closed-Loop Dynamics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FAST LAYER                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Agent (Q-learning, DQN, PPO, LLM, etc.)    â”‚   â”‚
â”‚  â”‚  â€¢ Perception  â€¢ Action  â€¢ Learning          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚              â†“ Metrics                    â†‘          â”‚
â”‚         (Ï, R, novelty)            Parameters        â”‚
â”‚              â†“                        (Îµ, Î±, Î³)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              â†“         SLOW LAYER          â†‘         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  GSV Controller: S(t) = [SA, SE, SP, SS]      â”‚  â”‚
â”‚  â”‚  â€¢ Stochastic Differential Equations          â”‚  â”‚
â”‚  â”‚  â€¢ Timescale: minutes (Ï„ ~ 50-200s)          â”‚  â”‚
â”‚  â”‚  â€¢ Bounded dynamics (cubic damping)           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Mathematical Formulation

The GSV dynamics are governed by **coupled Stochastic Differential Equations**:

```
dSA = [Î±AÂ·(ÏÌ„def + kAÂ·ExtStim) - Î³AÂ·SA - Î»AÂ·SAÂ³] dt + ÏƒAÂ·dWA

dSE = [Î±EÂ·(Rtarget - RÌ„) - Î³EÂ·SE - kAEÂ·tanh(SA)Â·SE - Î»EÂ·SEÂ³] dt + ÏƒEÂ·dWE

dSP = [Î±PÂ·(novelty + kPÂ·(Ftarget - FÌ„)) - Î³PÂ·SP - kPSÂ·tanh(SS)Â·SP - Î»PÂ·SPÂ³] dt + ÏƒPÂ·dWP

dSS = [Î±SÂ·SIR - Î³SÂ·SS - Î»SÂ·SSÂ³] dt + ÏƒSÂ·dWS
```

**Key innovations in GSV 2.0:**
- **Bounded cross-coupling**: `tanh(SA)` prevents runaway instability
- **Nonlinear damping**: `-Î»iÂ·SiÂ³` provides soft bounds without clipping
- **Stochastic terms**: Enable escape from local minima

---

## ğŸ“¦ Modules

### 1. `gsv2_core.py` - Core Implementation

**Classes:**
- `GSV2Params`: Parameter configuration with stability validation
  - `.conservative()`: Maximum stability
  - `.aggressive()`: Fast adaptation
  
- `GSV2Controller`: Main SDE solver
  - `.step()`: Euler-Maruyama integration
  - `.get_state()`: Current GSV state
  - `.compute_lyapunov()`: Stability monitoring
  
- `MetricComputer`: Compute GSV metrics from agent
  - `.compute_stress()`: TD error â†’ ÏÌ„def
  - `.compute_coherence()`: Policy entropy â†’ R
  - `.compute_novelty()`: State visits â†’ novelty rate
  
- `ModulationFunctions`: GSV â†’ Agent parameters
  - `.epsilon_exploration(SE)`: Exploration rate
  - `.alpha_learning(SP)`: Learning rate
  - `.gamma_discount(SA)`: Discount factor

### 2. `gsv2_qlearning.py` - Agent Integration

**Classes:**
- `QLearningAgent`: Standard Q-learning with modifiable hyperparameters
- `GSV2ModulatedQLearning`: Complete integration wrapper
- `SimpleGridworld`: Test environment with regime changes

### 3. `gsv2_analysis.py` - Diagnostics

**Classes:**
- `StabilityAnalyzer`: 
  - Jacobian eigenvalue computation
  - Lyapunov function analysis
  - Trajectory stability assessment
  
- `PhaseSpaceAnalyzer`:
  - Behavioral regime identification
  - Vector field computation
  - Attractor basin analysis
  
- `DiagnosticMonitor`:
  - Real-time health checks
  - Warning system
  - Status reporting

### 4. `gsv2_gridworld_demo.py` - Full Demo

**Classes:**
- `ExperimentRunner`: Manages complete experiments
- `ResultVisualizer`: Generates publication-quality plots

---

## ğŸ“Š Examples

### Example 1: Parameter Configurations

```python
from gsv2_core import GSV2Params

# Conservative (maximum stability)
params = GSV2Params.conservative()

# Balanced (recommended default)
params = GSV2Params()

# Aggressive (fast adaptation)
params = GSV2Params.aggressive()

# Custom
params = GSV2Params(
    alpha=np.array([0.1, 0.08, 0.05, 0.08]),
    gamma=np.array([0.015, 0.015, 0.01, 0.01]),
    k_AE=0.1,
    k_PS=0.05
)
```

### Example 2: Stability Analysis

```python
from gsv2_analysis import StabilityAnalyzer, DiagnosticMonitor

gsv = GSV2Controller(GSV2Params())
analyzer = StabilityAnalyzer(gsv)
monitor = DiagnosticMonitor(gsv)

# Check stability conditions
conditions = analyzer.check_stability_conditions()
print(f"System stable: {conditions['overall_stable']}")

# Compute eigenvalues
eigenvalues = analyzer.compute_eigenvalues()
print(f"Eigenvalues: {eigenvalues}")

# Monitor health
status = monitor.check_health()
print(f"Health: {status['health']}")
```

### Example 3: Custom Agent Integration

```python
class MyCustomAgent:
    def __init__(self):
        self.gsv = GSV2Controller()
        self.metrics = MetricComputer()
    
    def train_step(self, batch):
        # Your training logic
        loss = self.compute_loss(batch)
        
        # Compute metrics
        metrics = {
            'rho_def': loss / 10.0,  # Normalized stress
            'R': self.policy_entropy(),
            'novelty': self.compute_novelty(),
            'F': self.get_reward()
        }
        
        # Update GSV
        self.gsv.step(metrics, dt=1.0)
        
        # Modulate learning rate
        state = self.gsv.get_state()
        new_lr = ModulationFunctions.alpha_learning(state['P'])
        self.optimizer.lr = new_lr
```

---

## ğŸ“– Theory

### Stability Guarantee (Theorem 1)

**An equilibrium point S* of GSV 2.0 is locally stable if:**

```
Î³E > kAE - 3Î»E(SE*)Â²
```

For states near origin: **Î³E > kAE**

This is satisfied with balanced parameters:
- Î³E = 0.01
- kAE = 0.1 âœ“

### Lyapunov Function

```
V(S) = Î£[Â½SiÂ² + Â¼Î»iSiâ´]
```

**Property**: `dV/dt < 0` for ||S|| sufficiently large  
**Consequence**: Global attracting set exists

### Phase Space Regimes

| Regime | GSV State | Behavior |
|--------|-----------|----------|
| **Explorer** | [0.5, +1, +1, 0] | High exploration, high plasticity |
| **Guardian** | [+1, -1, -0.5, 0] | High arousal, exploitation mode |
| **Collaborator** | [0, 0, -0.5, +1] | Social coordination prioritized |
| **Adapter** | [0, +0.5, +1, -0.5] | Dynamic learning, individual focus |

---

## ğŸ”§ API Reference

### GSV2Controller

```python
class GSV2Controller:
    def __init__(self, params: GSV2Params = None)
    
    def step(self, metrics: Dict, dt: float = 1.0, 
             ext_stim: float = 0.0) -> np.ndarray
        """Single integration step"""
        
    def get_state(self) -> Dict[str, float]
        """Returns {'A': SA, 'E': SE, 'P': SP, 'S': SS}"""
        
    def reset(self)
        """Reset to initial state"""
        
    def compute_lyapunov(self) -> float
        """Compute V(S) for stability monitoring"""
```

### MetricComputer

```python
class MetricComputer:
    def __init__(self, window_size: int = 100, 
                 ewma_lambda: float = 0.05)
    
    def compute_stress(self, td_error: float) -> float
        """TD error â†’ stress [0, 1]"""
        
    def compute_coherence(self, policy_probs: np.ndarray) -> float
        """Policy entropy â†’ coherence [0, 1]"""
        
    def compute_novelty(self, state: int) -> float
        """State visitation â†’ novelty [0, 1]"""
        
    def compute_fitness(self, reward: float) -> float
        """Smoothed reward"""
```

### ModulationFunctions

```python
class ModulationFunctions:
    @staticmethod
    def epsilon_exploration(SE: float, 
                           eps_min: float = 0.1, 
                           eps_max: float = 0.5) -> float
    
    @staticmethod
    def alpha_learning(SP: float, 
                      alpha_base: float = 0.001, 
                      k_alpha: float = 0.5) -> float
    
    @staticmethod
    def gamma_discount(SA: float, 
                      gamma_base: float = 0.99, 
                      k_gamma: float = 0.1) -> float
    
    @staticmethod
    def temperature(SE: float, 
                   T_min: float = 0.5, 
                   T_max: float = 2.0) -> float
```

---

## ğŸ“ Research Context

### Connection to Active Inference

GSV components can be understood as **sufficient statistics of precision parameters** at the strategic timescale:

- **SA (Arousal)** ~ Expected precision on sensory prediction errors
- **SE (Exploration)** ~ Epistemic value weighting
- **SP (Plasticity)** ~ Learning rate meta-precision
- **SS (Social)** ~ Precision on social priors

The core dynamics (driving + decay terms) align with **gradient descent on hierarchical free energy**. Cross-coupling terms are functionally motivated by biological observations.

### Convergent Evolution Principle

Multi-scale control is a **universal architectural requirement** for any complex adaptive system operating across multiple timescales. Biological systems independently evolved this pattern:

```
Fast Layer (1-100ms):   Neural firing, immediate perception/action
Medium Layer (seconds): Working memory, attention
Slow Layer (minutes):   Neuromodulation (cortisol, dopamine)
```

GSV 2.0 is the artificial analog for autonomous agents.

---

## ğŸ“ˆ Expected Results

From the **Gridworld experiment** (3000 episodes, 2 regime changes):

**Phase 1 (0-1000): Initial Learning**
- Success rate: 0% â†’ 80%
- Exploration (Îµ): 0.5 â†’ 0.3
- GSV: SE peaks, then stabilizes

**Phase 2 (1000-2000): Regime Change**
- Success rate: drops to ~20%, recovers to 80%
- Exploration: spike to 0.5, gradual decay
- GSV: SA spike (stress), SE increase (exploration)

**Phase 3 (2000-3000): Second Regime Change**
- Pattern repeats, demonstrating **consistent adaptation**

---

## ğŸ¤ Contributing

This is a research implementation. Contributions welcome for:

- [ ] Additional agent integrations (DQN, PPO, A3C)
- [ ] LLM-specific metrics and modulation
- [ ] Multi-agent scenarios with SS axis
- [ ] Empirical validation on complex benchmarks
- [ ] Formal derivation of cross-coupling terms from FEP
- [ ] JAX/GPU acceleration

---

## ğŸ“š Citation

```bibtex
@article{urmanov2025gsv2,
  title={Global State Vector 2.0: Multi-Scale Control for Autonomous AI Agents},
  author={Urmanov, Timur and Gadeev, Kamil and Iusupov, Bakhtier},
  year={2025},
  note={Theoretical Proposal for Discussion}
}
```

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ”— Related Work

- **Active Inference**: Friston, K. (2010). *The free-energy principle: a unified brain theory?*
- **Meta-RL**: Finn et al. (2017). *Model-Agnostic Meta-Learning (MAML)*
- **Neuromodulation**: Yu & Dayan (2005). *Uncertainty, neuromodulation, and attention*
- **Hierarchical RL**: Sutton et al. (1999). *Temporal abstraction in RL*

---

## ğŸ“ Contact

- **Timur Urmanov**: urmanov.t@gmail.com
- **Kamil Gadeev**: gadeev.kamil@gmail.com
- **Bakhtier Iusupov**: usupovbahtiayr@gmail.com

---

**Status**: âœ… MVP Complete | ğŸš§ Empirical Validation Pending

*"The need for hierarchical, multi-scale control is not peculiar to artificial agents but represents a universal architectural requirement for any complex adaptive system."*